import { NextRequest, NextResponse } from 'next/server'
import { MCPService } from '@/lib/ai/mcp-service'

// MCP servisini baÅŸlat - her request iÃ§in yeni instance
// BÃ¶ylece environment variable'lar dÃ¼zgÃ¼n yÃ¼klenir
function getMCPService() {
  return new MCPService()
}

export async function POST(request: NextRequest) {
  
  try {
    const formData = await request.formData()
    const image = formData.get('image') as File | null
    const subject = formData.get('subject') as string
    const examType = formData.get('examType') as 'TYT' | 'AYT' || 'TYT'
    const preferredModel = formData.get('model') as any || 'auto'
    const requireMultipleModels = formData.get('multiModel') === 'true'



    if (!image) {
      return NextResponse.json(
        { error: 'LÃ¼tfen soru gÃ¶rselini yÃ¼kleyin.' },
        { status: 400 }
      )
    }

    if (!subject) {
      return NextResponse.json(
        { error: 'LÃ¼tfen ders seÃ§in.' },
        { status: 400 }
      )
    }

    if (!process.env.GEMINI_API_KEY || process.env.GEMINI_API_KEY === 'your_gemini_api_key_here') {
      
      const demoSolution = generateDemoSolution(subject, examType, preferredModel)
      return NextResponse.json({
        solution: demoSolution,
        model: preferredModel || 'gemini',
        confidence: 0.85,
        processingTime: 1500,
        examType,
        isDemoMode: true
      })
    }

    const imageBuffer = await image.arrayBuffer()
    const base64Image = Buffer.from(imageBuffer).toString('base64')
    const mimeType = image.type || 'image/jpeg'


    // MCP servisi oluÅŸtur
    const mcpService = getMCPService()

    // MCP ile Ã§Ã¶zÃ¼m al
    const responses = await mcpService.solve({
      image: base64Image,
      mimeType,
      subject,
      examType,
      preferredModel: preferredModel === 'auto' ? undefined : preferredModel,
      requireMultipleModels
    })


    if (requireMultipleModels && responses.length > 1) {
      return NextResponse.json({
        solutions: responses,
        examType,
        multiModel: true
      })
    } else {
      const bestResponse = responses[0]
      
      if (!bestResponse || bestResponse.error) {
        console.error('MCP API: Ã‡Ã¶zÃ¼m hatasÄ±:', bestResponse?.error)
        throw new Error(bestResponse?.error || 'Ã‡Ã¶zÃ¼m oluÅŸturulamadÄ±')
      }

      return NextResponse.json({
        solution: bestResponse.solution,
        model: bestResponse.model,
        confidence: bestResponse.confidence,
        processingTime: bestResponse.processingTime,
        examType,
        error: bestResponse.error
      })
    }

  } catch (error) {
    console.error('MCP API Error:', error)
    
    const errorMessage = error instanceof Error ? error.message : 'Bir hata oluÅŸtu'
    
    return NextResponse.json(
      { 
        error: errorMessage,
        details: process.env.NODE_ENV === 'development' ? error : undefined
      },
      { status: 500 }
    )
  }
}

function generateDemoSolution(subject: string, examType: string, model: string): string {
  const modelName = model === 'gemini' ? 'Google Gemini' 
    : model === 'claude' ? 'Claude 3'
    : model === 'gpt' ? 'GPT-4 Vision'
    : model === 'ollama' ? 'Ollama'
    : 'Otomatik SeÃ§im'

  return `**ğŸ¯ DEMO MODU - ${examType} ${subject.toUpperCase()} Ã‡Ã–ZÃœM**

âš ï¸ **API AnahtarÄ± Gerekli**
GerÃ§ek Ã§Ã¶zÃ¼mler iÃ§in Google Gemini API anahtarÄ± ekleyin.

ğŸ“š **Model: ${modelName}**
MCP teknolojisi ile Ã§oklu model desteÄŸi

**ğŸ”§ Kurulum:**
1. Google AI Studio'dan Ã¼cretsiz API key alÄ±n
2. .env.local dosyasÄ±na ekleyin:
   GEMINI_API_KEY=your_api_key_here

**âœ¨ MCP Ã–zellikleri:**
- Otomatik model seÃ§imi
- Ã‡oklu model karÅŸÄ±laÅŸtÄ±rmasÄ±
- Cache sistemi ile hÄ±zlÄ± yanÄ±t
- Fallback mekanizmasÄ±

**ğŸ“Š Model Yetenekleri:**
${model === 'gemini' ? '- HÄ±zlÄ± gÃ¶rsel analiz\n- Pratik Ã§Ã¶zÃ¼mler\n- Ãœcretsiz kullanÄ±m'
  : model === 'claude' ? '- DetaylÄ± mantÄ±ksal analiz\n- AdÄ±m adÄ±m aÃ§Ä±klamalar\n- YÃ¼ksek doÄŸruluk'
  : model === 'gpt' ? '- YaratÄ±cÄ± Ã§Ã¶zÃ¼mler\n- Alternatif yaklaÅŸÄ±mlar\n- Ã‡oklu perspektif'
  : model === 'ollama' ? '- Yerel Ã§alÄ±ÅŸma\n- Gizlilik odaklÄ±\n- Ä°nternet gerektirmez'
  : '- En uygun model otomatik seÃ§ilir\n- YÃ¼ksek baÅŸarÄ± oranÄ±\n- AkÄ±llÄ± yÃ¶nlendirme'}

**ğŸ’¡ ${examType} Ä°puÃ§larÄ±:**
${examType === 'TYT' 
  ? '- Temel kavramlara odaklanÄ±n\n- Zaman yÃ¶netimi kritik\n- Pratik Ã§Ã¶zÃ¼m yÃ¶ntemleri Ã¶ÄŸrenin'
  : '- DetaylÄ± analiz yapÄ±n\n- Konular arasÄ± baÄŸlantÄ± kurun\n- FarklÄ± Ã§Ã¶zÃ¼m stratejileri deneyin'}`
}

export async function GET() {
  try {
    const mcpService = getMCPService()
    const modelStatus = mcpService.getModelStatus()
    
    return NextResponse.json({
      models: {
        gemini: {
          name: 'Google Gemini 1.5 Flash',
          description: 'HÄ±zlÄ± gÃ¶rsel analiz ve pratik Ã§Ã¶zÃ¼mler',
          enabled: modelStatus.gemini,
          features: ['GÃ¶rsel analiz', 'HÄ±zlÄ± Ã§Ã¶zÃ¼m', 'Ãœcretsiz kullanÄ±m'],
          icon: 'ğŸš€'
        },
        claude: {
          name: 'Anthropic Claude 3',
          description: 'DetaylÄ± mantÄ±ksal analiz ve aÃ§Ä±klamalar',
          enabled: modelStatus.claude,
          features: ['Derin analiz', 'AdÄ±m adÄ±m Ã§Ã¶zÃ¼m', 'YÃ¼ksek doÄŸruluk'],
          icon: 'ğŸ§ '
        },
        gpt: {
          name: 'OpenAI GPT-4 Vision',
          description: 'YaratÄ±cÄ± Ã§Ã¶zÃ¼mler ve alternatif yaklaÅŸÄ±mlar',
          enabled: modelStatus.gpt,
          features: ['Ã‡oklu Ã§Ã¶zÃ¼m', 'YaratÄ±cÄ± yaklaÅŸÄ±m', 'GÃ¶rsel anlama'],
          icon: 'ğŸ¨'
        },
        ollama: {
          name: 'Ollama (Yerel Model)',
          description: 'Ä°nternet gerektirmeyen yerel Ã§Ã¶zÃ¼m',
          enabled: modelStatus.ollama,
          features: ['Gizlilik', 'Ã‡evrimdÄ±ÅŸÄ±', 'HÄ±zlÄ± yanÄ±t'],
          icon: 'ğŸ '
        }
      },
      capabilities: {
        multiModel: true,
        autoSelect: true,
        fallback: true,
        caching: true
      }
    })
  } catch (error) {
    console.error('Model status error:', error)
    return NextResponse.json({
      models: {},
      capabilities: {},
      error: 'Model durumu alÄ±namadÄ±'
    })
  }
} 